{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02d7ea4b-2e5b-44de-ae28-4ad506a0333b",
   "metadata": {},
   "source": [
    "# Домашнее задание. Классификация изображений\n",
    "\n",
    "Сегодня вам предстоить помочь телекомпании FOX в обработке их контента. Как вы знаете, сериал \"Симпсоны\" идет на телеэкранах более 25 лет, и за это время скопилось очень много видеоматериала. Персоонажи менялись вместе с изменяющимися графическими технологиями, и Гомер Симпсон-2018 не очень похож на Гомера Симпсона-1989. В этом задании вам необходимо классифицировать персонажей, проживающих в Спрингфилде. Думаю, нет смысла представлять каждого из них в отдельности."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bf698e-6dfa-4ba9-9e64-d6e001f976e0",
   "metadata": {},
   "source": [
    "**Мое имя на в leaderboard на kaggle - Dmitriy_Zharkovskiy_562531453**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804c36b8-778a-4e9a-b533-1dcc7717c363",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch_lightning\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8f71779-cac2-48a7-b2a3-21262041fda1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov 12 19:00:19 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 536.67                 Driver Version: 536.67       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3060 Ti   WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| 90%   31C    P8              21W / 200W |    357MiB /  8192MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1640    C+G   ...aming\\Telegram Desktop\\Telegram.exe    N/A      |\n",
      "|    0   N/A  N/A      3032    C+G   ....0_x64__8wekyb3d8bbwe\\HxOutlook.exe    N/A      |\n",
      "|    0   N/A  N/A      6740    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
      "|    0   N/A  N/A      7544    C+G   ...0_x64__8wekyb3d8bbwe\\HxAccounts.exe    N/A      |\n",
      "|    0   N/A  N/A      7772    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      8184    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      8488    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A      9748    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     10284    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     10432    C+G   ...GeForce Experience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A     10664    C+G   ...GeForce Experience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A     11704    C+G   ...e Stream\\83.0.2.0\\GoogleDriveFS.exe    N/A      |\n",
      "|    0   N/A  N/A     12056    C+G   ...oogle\\Chrome\\Application\\chrome.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import random\n",
    "import os\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from sklearn.metrics import f1_score\n",
    "from torchmetrics.classification import MulticlassConfusionMatrix\n",
    "from matplotlib import colors, pyplot as plt\n",
    "import warnings\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd4bfc4d-6243-4682-824c-0a09c3cc1ca5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_MODES = ['train', 'val', 'test']\n",
    "RESCALE_SIZE = 299\n",
    "DEVICE =  torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c149f25-7da4-49f1-9d1e-3b597d395540",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    # Фискирует максимум сидов.\n",
    "    # Это понадобится, чтобы сравнение оптимизаторов было корректным\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0999a767-d394-43de-b2bc-6ed3b4f5cfed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpsonsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Датасет с картинками, который паралельно подгружает их из папок\n",
    "    производит скалирование и превращение в торчевые тензоры\n",
    "    \"\"\"\n",
    "    def __init__(self, files, mode, transform):\n",
    "        super().__init__()\n",
    "        # список файлов для загрузки\n",
    "        self.files = sorted(files)\n",
    "        # режим работы\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "\n",
    "        if self.mode not in DATA_MODES:\n",
    "            print(f\"{self.mode} is not correct; correct modes: {DATA_MODES}\")\n",
    "            raise NameError\n",
    "\n",
    "        self.len_ = len(self.files)\n",
    "\n",
    "        self.label_encoder = LabelEncoder()\n",
    "\n",
    "        if self.mode != 'test':\n",
    "            self.labels = [path.parent.name for path in self.files]\n",
    "            self.label_encoder.fit(self.labels)\n",
    "\n",
    "            with open('label_encoder.pkl', 'wb') as le_dump_file:\n",
    "                  pickle.dump(self.label_encoder, le_dump_file)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len_\n",
    "\n",
    "    def load_sample(self, file):\n",
    "        image = Image.open(file)\n",
    "        image.load()\n",
    "        return image\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # для преобразования изображений в тензоры PyTorch и нормализации входа\n",
    "        x = self.load_sample(self.files[index])\n",
    "        x = self._prepare_sample(x)\n",
    "        x = self.transform(x)\n",
    "\n",
    "        if self.mode == 'test':\n",
    "            return x\n",
    "        else:\n",
    "            label = self.labels[index]\n",
    "            label_id = self.label_encoder.transform([label])\n",
    "            y = label_id.item()\n",
    "            return x, y\n",
    "\n",
    "    def _prepare_sample(self, image):\n",
    "        image = image.resize((RESCALE_SIZE, RESCALE_SIZE))\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea1e5d14-f107-4612-8be1-d72900e2e4b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = Path('train/')\n",
    "TEST_DIR = Path('testset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd20d42e-51ba-4d05-8bc1-1319679ad554",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_val_files = sorted(list(TRAIN_DIR.rglob('*.jpg')))\n",
    "test_files = sorted(list(TEST_DIR.rglob('*.jpg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "872fc303-34a4-43e7-996c-891e7698d127",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_val_labels = [path.parent.name for path in train_val_files]\n",
    "train_files, val_files = train_test_split(train_val_files, test_size=0.25, \\\n",
    "                                          stratify=train_val_labels, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f9d362b-6608-4603-b1b8-18f31202824b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = SimpsonsDataset(train_files, mode='train', transform=transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    "))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7a8af1-ab44-4d62-ab03-0353df25b010",
   "metadata": {},
   "source": [
    "#### Посчитаем среднее и стандартное отклонение по каналам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef60f7ea-3281-4ba1-ad9d-bdfec6645ced",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [01:24<00:00,  2.90it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.4625, 0.4077, 0.3520], device='cuda:0'),\n",
       " tensor([0.2503, 0.2285, 0.2603], device='cuda:0'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = torch.FloatTensor([0, 0, 0]).to(DEVICE)\n",
    "std = torch.FloatTensor([0, 0, 0]).to(DEVICE)\n",
    "\n",
    "for data, _ in tqdm(train_dataloader):\n",
    "    data = data.to(DEVICE)\n",
    "    mean += data.mean(dim=(0, 2, 3))\n",
    "    std += data.std(dim=(0, 2, 3))\n",
    "mean /= len(train_dataloader)\n",
    "std /= len(train_dataloader)\n",
    "mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9021101-ad6c-4df5-9c54-ac83d0232e50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpsonsNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = models.densenet161(\n",
    "            weights=models.DenseNet161_Weights.IMAGENET1K_V1\n",
    "        )\n",
    "        self.model.classifier = nn.Linear(2208, 42)\n",
    "\n",
    "        params_to_update = []\n",
    "        update_params_name = [\n",
    "            name for name, _ in self.model.named_parameters()\n",
    "        ][-22:]\n",
    "\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if name in update_params_name:\n",
    "                param.requires_grad = True\n",
    "                params_to_update.append(param)\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "                \n",
    "        # Set Optimizer\n",
    "        self.optimizer = optim.AdamW(params=params_to_update, lr=1e-3)      \n",
    "        \n",
    "        self.loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        self.targets = torch.Tensor()\n",
    "        self.preds = torch.Tensor()\n",
    "\n",
    "    def _forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, images, target=None):\n",
    "        output = self._forward(images)\n",
    "\n",
    "        if target is not None:\n",
    "            loss = self.loss_func(output, target)\n",
    "\n",
    "            self.targets = torch.cat((self.targets, target.cpu()), 0)\n",
    "            pred = torch.argmax(output, dim=-1)\n",
    "            self.preds = torch.cat((self.preds, pred.cpu()), 0)\n",
    "            return loss\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ec1c16e-f634-4493-88ba-f975dc965df0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean.cpu(), std.cpu())\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean.cpu(), std.cpu())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89a367b3-9f05-492f-bf1e-8bc1737701f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = SimpsonsDataset(train_files, mode='train', transform=train_transform)\n",
    "val_dataset = SimpsonsDataset(val_files, mode='val', transform=val_transform)\n",
    "test_dataset = SimpsonsDataset(test_files, mode='test', transform=val_transform)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=64)\n",
    "val_dataloader = DataLoader(val_dataset, shuffle=False, batch_size=128)\n",
    "test_dataloader = DataLoader(test_dataset, shuffle=False, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86913f6-af67-421a-86eb-02b2b9a0ff23",
   "metadata": {},
   "source": [
    "#### Реализую тренировочный цикл с помощью pytorch lightning он намного удобнее и по моим наблюдениям работает намного быстрее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29dfce0a-aa16-4e3a-bfd4-5f65aca545cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainModule(pl.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.best_loss = None\n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        result = self.model(x)\n",
    "        return result\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = self.model.optimizer\n",
    "        lambda_func = lambda epoch: 0.975 ** epoch\n",
    "        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_func)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        images, target = train_batch\n",
    "        loss = self.model(images, target)\n",
    "        self.log(\n",
    "            \"train_loss\", loss, prog_bar=True\n",
    "        )\n",
    "        self.train_loss.append(loss.item())\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        images, target = val_batch\n",
    "        loss = self.model(images, target)\n",
    "        self.val_loss.append(loss.item())\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = loss\n",
    "        if loss < self.best_loss:\n",
    "            self.best_loss = loss\n",
    "            torch.save(self.model, 'autosavemodel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2900be26-5d77-4f4f-8730-0bc3c6c5e619",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = SimpsonsNet().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2dd0887-4d14-4c74-8d0d-ad1bd90c000a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgarkovski_dmitri\u001b[0m (\u001b[33mkuban23_\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "wandb.login()\n",
    "wandb_logger = WandbLogger(log_model='all', name='densenet161 --denselayer22-- optim.AdamW(params=params_to_update, lr=1e-3)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9089e106-72ae-4589-aacc-e6c99d423d33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "module = TrainModule(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10b08204-4a7e-40df-95f1-58d996142924",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed_everything(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e2ef589-159c-4eff-a231-296d4fff5bdd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13f07b8e6bbb439c928a20883984ed33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011111111111111112, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20231112_190439-he26efzm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kuban23_/lightning_logs/runs/he26efzm' target=\"_blank\">densenet161 --denselayer22-- optim.AdamW(params=params_to_update, lr=1e-3)</a></strong> to <a href='https://wandb.ai/kuban23_/lightning_logs' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kuban23_/lightning_logs' target=\"_blank\">https://wandb.ai/kuban23_/lightning_logs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kuban23_/lightning_logs/runs/he26efzm' target=\"_blank\">https://wandb.ai/kuban23_/lightning_logs/runs/he26efzm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type        | Params\n",
      "--------------------------------------\n",
      "0 | model | SimpsonsNet | 26.6 M\n",
      "--------------------------------------\n",
      "1.6 M     Trainable params\n",
      "25.0 M    Non-trainable params\n",
      "26.6 M    Total params\n",
      "106.259   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\py310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=5` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\user\\anaconda3\\envs\\py310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=5` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f904bec9b64025835a1dacd186e242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=7` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(logger=wandb_logger, accelerator=\"gpu\", max_epochs=7)\n",
    "trainer.fit(module, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99e25c93-82c8-407d-bd2e-948179365c40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>train_loss</td><td>█▅▅▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>val_loss</td><td>█▄▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>6</td></tr><tr><td>train_loss</td><td>0.0062</td></tr><tr><td>trainer/global_step</td><td>1721</td></tr><tr><td>val_loss</td><td>0.14041</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">densenet161 --denselayer22-- optim.AdamW(params=params_to_update, lr=1e-3)</strong> at: <a href='https://wandb.ai/kuban23_/lightning_logs/runs/he26efzm' target=\"_blank\">https://wandb.ai/kuban23_/lightning_logs/runs/he26efzm</a><br/>Synced 6 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231112_190439-he26efzm\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf771634-e05a-4e14-a6ca-0016337d298e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = model.to(DEVICE)\n",
    "y_pred = torch.tensor([])\n",
    "actual_labels = torch.tensor([])\n",
    "for img, labels in val_dataloader:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        probs = model(img.to(DEVICE))\n",
    "        preds = np.argmax(probs.cpu(), axis=1)\n",
    "        y_pred = torch.cat((y_pred, preds))\n",
    "        actual_labels = torch.cat((actual_labels, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be50abff-a1ee-4d88-9b29-9f2ae4401b89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-оценка: 0.965418418035919\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(actual_labels, y_pred, average='micro')\n",
    "print(\"F1-оценка:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c6328d4-8bf1-4e75-8414-87647fc76721",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = SimpsonsDataset(test_files, mode=\"test\", transform=val_transform)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=64)\n",
    "\n",
    "y_pred = torch.tensor([])\n",
    "\n",
    "for img in test_dataloader:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        probs = model(img.to(DEVICE))\n",
    "        preds = np.argmax(probs.cpu(), axis=1)\n",
    "        y_pred = torch.cat((y_pred, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52ce7e67-65df-4aed-bed1-bb32365edbe5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = train_dataset.label_encoder.inverse_transform(y_pred.numpy().astype(int))\n",
    "test_filenames = [path.name for path in test_dataset.files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96490491-01b9-4096-ba15-898375a17870",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_submit = pd.DataFrame({'Id': test_filenames, 'Expected': preds})\n",
    "my_submit.to_csv('my_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf61a4c-328a-473c-9aec-75d7da491a94",
   "metadata": {},
   "source": [
    "**F1 на kaggle - 0.98724**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5f1b18-77f9-4a70-af39-f4f282f952cf",
   "metadata": {},
   "source": [
    "**Мое имя на в leaderboard на kaggle - Dmitriy_Zharkovskiy_562531453**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc8e9d9-cbf3-499c-8559-4b69a7114575",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
